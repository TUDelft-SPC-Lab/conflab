{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Subset\n",
    "import pytorch_lightning as pl\n",
    "from tqdm.notebook import trange\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from system import System\n",
    "from conflab.data_loading.pose import ConflabPoseExtractor\n",
    "from conflab.data_loading.accel import ConflabAccelExtractor\n",
    "from conflab.data_loading.person import ConflabDataset, ConflabSubset\n",
    "from conflab.data_loading.labels import ConflabLabelExtractor\n",
    "from conflab.constants import conflab_pose_path, midge_data_path, conflab_speaking_status_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fold(train_ds, test_ds, model_name='resnet', model_hparams={}, deterministic=False, log_prefix=None):\n",
    "    # split the train set into train and val\n",
    "    # use 10% of data for val\n",
    "    val_ds, train_ds = train_ds.random_split(0.1)\n",
    "\n",
    "    # data loaders\n",
    "    data_loader_train = torch.utils.data.DataLoader(\n",
    "        train_ds, batch_size=64, shuffle=True, num_workers=4,\n",
    "        collate_fn=None)\n",
    "    data_loader_val = torch.utils.data.DataLoader(\n",
    "        val_ds, batch_size=128, shuffle=False, num_workers=4,\n",
    "        collate_fn=None)\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        test_ds, batch_size=128, shuffle=False, num_workers=4,\n",
    "        collate_fn=None)\n",
    "\n",
    "    system = System(model_name, model_hparams=model_hparams)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(dirpath=\"./checkpoints\", save_top_k=1, mode=\"max\", monitor=\"val_auc\")\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor=\"val_auc\", patience=6, mode=\"max\"),\n",
    "            checkpoint_callback\n",
    "        ],\n",
    "        accelerator='gpu',\n",
    "        log_every_n_steps=1,\n",
    "        max_epochs=20,\n",
    "        deterministic=deterministic,\n",
    "        logger=pl.loggers.TensorBoardLogger(save_dir=\"logs/\", version=log_prefix))\n",
    "    trainer.fit(system, data_loader_train, data_loader_val)\n",
    "\n",
    "    trainer.test(system, data_loader_test, ckpt_path='best')\n",
    "    return system.test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(outputs, labels, type='binary'):\n",
    "    if type == 'binary':\n",
    "        proba = torch.sigmoid(outputs)\n",
    "        pred = (proba > 0.5)\n",
    "\n",
    "        correct = pred.eq(labels).sum().item()\n",
    "        return {\n",
    "            'auc': roc_auc_score(labels, proba),\n",
    "            'acc': correct / len(outputs),\n",
    "            'correct': correct\n",
    "        }\n",
    "    elif type == 'regression':\n",
    "        return {\n",
    "            'mse': torch.nn.functional.mse_loss(outputs, labels, reduction='mean'),\n",
    "            'l1': torch.nn.functional.l1_loss(outputs, labels, reduction='mean')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_run(dataset, model_name, random_state, metrics_name='binary', deterministic=False, log_prefix='cv'):\n",
    "    # split per pid\n",
    "    pids = set(dataset.get_groups())\n",
    "    pid_splits = KFold(n_splits=10, random_state=random_state, shuffle=True).split(range(len(pids)))\n",
    "\n",
    "    outputs = torch.empty((len(dataset),))\n",
    "    for f, (train_pids, test_pids) in enumerate(pid_splits):\n",
    "        # create datasets   \n",
    "        train_idx = [i for i, e in enumerate(dataset.examples) if e[0] in train_pids]\n",
    "        test_idx = [i for i, e in enumerate(dataset.examples) if e[0] in test_pids]\n",
    "        print(f'ds split into {len(train_idx)} train and {len(test_idx)} test')\n",
    "\n",
    "        train_ds = ConflabSubset(dataset, train_idx)\n",
    "        test_ds = ConflabSubset(dataset, test_idx)\n",
    "\n",
    "        c_in = dataset.extractors['accel'].num_columns\n",
    "        model_hparams = {'c_in': c_in} \n",
    "\n",
    "        fold_outputs = do_fold(train_ds, test_ds, \n",
    "            model_name, \n",
    "            model_hparams,\n",
    "            deterministic=deterministic, \n",
    "            log_prefix=log_prefix+f'_fold{f}')\n",
    "            \n",
    "        outputs[test_idx] = fold_outputs['proba'].cpu()\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    labels = torch.Tensor(dataset.get_all_labels())\n",
    "    run_metrics = get_metrics(outputs, labels, metrics_name)\n",
    "\n",
    "    return outputs, run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_extractor = ConflabPoseExtractor(conflab_pose_path)\n",
    "pose_extractor.load_from_pickle('../tracks.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_extractor = ConflabAccelExtractor(midge_data_path, columns=['accelX', 'accelY', 'accelZ'])\n",
    "sensor_extractor = ConflabAccelExtractor(midge_data_path)\n",
    "label_extractor = ConflabLabelExtractor(os.path.join(conflab_speaking_status_path, 'speaking'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 591.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# make windowed examples using the pose tracks.\n",
    "examples = pose_extractor.make_examples()\n",
    "# compose the dataset\n",
    "accel_ds = ConflabDataset(examples, {\n",
    "    'accel': accel_extractor,\n",
    "    'label': label_extractor\n",
    "})\n",
    "sensor_ds = ConflabDataset(examples, {\n",
    "    'accel': sensor_extractor,\n",
    "    'label': label_extractor\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataset\n",
    "for i in range(len(sensor_ds)):\n",
    "    assert sensor_ds[i]['accel'].shape[0] == 150, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('paper_runs')\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    f_handler = logging.FileHandler('paper_runs.csv', mode='w')\n",
    "    logger.addHandler(f_handler)\n",
    "\n",
    "datasets = {\n",
    "    'all': sensor_ds,\n",
    "    'accel': accel_ds\n",
    "}\n",
    "\n",
    "def do_paper_runs():\n",
    "    results = {}\n",
    "    # for model_name in ['minirocket', 'inception', 'resnet']:\n",
    "    for model_name in ['inception', 'resnet']:\n",
    "        model_results = {}\n",
    "\n",
    "        for features in ['all', 'accel']:\n",
    "            seed=22\n",
    "            pl.utilities.seed.seed_everything(seed, workers=True)\n",
    "            proba, metrics = do_run(\n",
    "                datasets[features], \n",
    "                model_name, \n",
    "                random_state=seed, \n",
    "                metrics_name='binary', \n",
    "                deterministic=True, \n",
    "                log_prefix=f\"{model_name}_{features}\")\n",
    "            model_results[features] = metrics\n",
    "            pd.DataFrame(proba.numpy()).to_csv(\n",
    "                os.path.join('outputs', f\"{model_name}_{features}.csv\"),\n",
    "                header=False,\n",
    "                index=False)\n",
    "            logger.info(f\"{model_name}, {features}, {metrics['auc']}, {metrics['acc']}\")\n",
    "        results[model_name] = model_results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inception': {'all': {'auc': 0.6881288608492249,\n",
       "   'acc': 0.7291870714985309,\n",
       "   'correct': 31269},\n",
       "  'accel': {'auc': 0.7985812018585552,\n",
       "   'acc': 0.7675714752110443,\n",
       "   'correct': 32915}},\n",
       " 'resnet': {'all': {'auc': 0.6860748897127408,\n",
       "   'acc': 0.7216081339489763,\n",
       "   'correct': 30944},\n",
       "  'accel': {'auc': 0.8008403875320723,\n",
       "   'acc': 0.7731449092859475,\n",
       "   'correct': 33154}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_paper_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ff63645dd16f55240e07095d3c46f4fac3f89ef16802cfaceca713f6cf38dfb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
